{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  9 08:17:57 2023\n",
    "\n",
    "@author: Joao\n",
    "\n",
    "This script reads a training CSV, outputs predictions for the data, and applies\n",
    "the score metric to compute the final score. \n",
    "\n",
    "It also computes a few other known metrics, like top-k accuracy and average power loss.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 'F5' Começa a debuger o codigo \n",
    "# 'F10' Analisar a linha sem entrar no codigo \n",
    "# 'F11' Analisar linha  e entrar no codigo \n",
    "# 'SHIFT-F11' sair do bloco de codigo atual e continuar a execução\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_SIZE = 5      # 5 input samples\n",
    "N_GPS = 2       # 2 GPSs (unit1 and unit2)\n",
    "N_GPS_COORD = 2 # 2 GPS coords (latitude & longitude)\n",
    "N_ARR = 4       # 4 arrays\n",
    "N_BEAMS = 64    # 64 beams per array\n",
    "IDX_COL1 = 'unique_index' # index col in the training CSV\n",
    "IDX_COL2 = 'abs_index'    # index col in the CSVs of the V2V dataset \n",
    "                          # this indices are the same, just dif names\n",
    "\n",
    "def norm_2pi(x):\n",
    "    x_normed = np.empty_like(x)\n",
    "    x_normed[:] = x\n",
    "    for i in range(len(x)):\n",
    "        if abs(x[i]) >= np.pi:\n",
    "            x_normed[i] = x[i] % (2*np.pi)\n",
    "\n",
    "            if x[i] >= np.pi:\n",
    "                x_normed[i] -= 2*np.pi\n",
    "\n",
    "        while x_normed[i] < -np.pi:\n",
    "            x_normed[i] += 2*np.pi\n",
    "\n",
    "        while x_normed[i] > np.pi:\n",
    "            x_normed[i] -= 2*np.pi\n",
    "\n",
    "        if x_normed[i] < -np.pi:\n",
    "            print(f'{i}, {x_normed[i]}')\n",
    "\n",
    "    return x_normed\n",
    "\n",
    "\n",
    "def compute_ori_from_pos_delta(lat_deltas, lon_deltas):\n",
    "\n",
    "    n_samples = len(lat_deltas)\n",
    "    pose = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        delta_lat = lat_deltas[i-1]\n",
    "        delta_lon = lon_deltas[i-1]\n",
    "\n",
    "        if delta_lon == 0:\n",
    "            if delta_lat == 0:\n",
    "                pose[i] = 0\n",
    "                continue\n",
    "            elif delta_lat > 0:\n",
    "                slope = np.pi / 2\n",
    "            elif delta_lat < 0:\n",
    "                slope = -np.pi / 2\n",
    "        else:\n",
    "            slope = np.arctan(delta_lat / delta_lon)\n",
    "            if delta_lat == 0:\n",
    "                slope = np.pi if delta_lon < 0 else 0\n",
    "            elif delta_lat < 0 and delta_lon < 0:\n",
    "                slope = -np.pi + slope\n",
    "            elif delta_lon < 0 and delta_lat > 0:\n",
    "                slope = np.pi + slope\n",
    "\n",
    "        pose[i] = slope\n",
    "\n",
    "    return pose\n",
    "\n",
    "\n",
    "def estimate_positions(input_positions, delta_input, delta_output):\n",
    "\n",
    "        # Calculate the number of samples in the input positions array\n",
    "    n_samples = input_positions.shape[0]\n",
    "\n",
    "    # Initialize an array to store the estimated output positions\n",
    "    out_pos = np.zeros((n_samples, 2))\n",
    "\n",
    "    # Determine the size of each input position array (number of samples)\n",
    "    x_size = input_positions.shape[1]\n",
    "\n",
    "    # Define the time points corresponding to each sample in the input positions array\n",
    "    x = delta_input * np.arange(x_size)\n",
    "\n",
    "    # Iterate over each sample to estimate the corresponding output position\n",
    "    for sample_idx in tqdm(range(n_samples), desc='Estimating input positions'):\n",
    "        # Extract the input positions for the current sample\n",
    "        input_pos = input_positions[sample_idx]\n",
    "\n",
    "        # Perform linear interpolation to estimate latitude and longitude at the output time\n",
    "        f_lat = scipy.interpolate.interp1d(x, input_pos[:, 0], fill_value='extrapolate')\n",
    "        f_lon = scipy.interpolate.interp1d(x, input_pos[:, 1], fill_value='extrapolate')\n",
    "\n",
    "        # Calculate the estimated latitude and longitude at the output time\n",
    "        out_pos[sample_idx, 0] = f_lat(x[-1] + delta_output)\n",
    "        out_pos[sample_idx, 1] = f_lon(x[-1] + delta_output)\n",
    "\n",
    "    # Return the array of estimated output positions\n",
    "    return out_pos\n",
    "\n",
    "\n",
    "\n",
    "def predict_beam_uniformly_from_aoa(aoa):\n",
    "\n",
    "    beam_predictions = np.zeros_like(aoa)\n",
    "\n",
    "    beam_ori = np.arange(N_BEAMS * N_ARR) / (N_BEAMS * N_ARR - 1) * 2*np.pi - np.pi\n",
    "\n",
    "    angl_diff_to_each_beam = aoa.reshape((-1, 1)) - beam_ori\n",
    "\n",
    "    beam_predictions = np.argsort(abs(angl_diff_to_each_beam), axis=1)\n",
    "\n",
    "    return beam_predictions\n",
    "\n",
    "\n",
    "def circular_distance(a, b, l=256, sign=False):\n",
    "\n",
    "    while a < 0:\n",
    "        a = l - abs(a)\n",
    "    while b < 0:\n",
    "        b = l - abs(b)\n",
    "        \n",
    "    a = a % l if a >= l else a\n",
    "    b = b % l if b >= l else b\n",
    "    \n",
    "    dist = a - b\n",
    "\n",
    "    if abs(dist) > l/2:\n",
    "        dist = l - abs(dist)\n",
    "\n",
    "    return dist if sign else abs(dist)\n",
    "\n",
    "\n",
    "def compute_acc(all_beams, only_best_beam, top_k=[1, 3, 5]):\n",
    "    \n",
    "\n",
    "    n_top_k = len(top_k)\n",
    "    total_hits = np.zeros(n_top_k)\n",
    "\n",
    "    n_test_samples = len(only_best_beam)\n",
    "    if len(all_beams) != n_test_samples:\n",
    "        raise Exception(\n",
    "            'Number of predicted beams does not match number of labels.')\n",
    "\n",
    "    # For each test sample, count times where true beam is in k top guesses\n",
    "    for samp_idx in range(len(only_best_beam)):\n",
    "        for k_idx in range(n_top_k):\n",
    "            hit = np.any(all_beams[samp_idx, :top_k[k_idx]] == only_best_beam[samp_idx])\n",
    "            total_hits[k_idx] += 1 if hit else 0\n",
    "\n",
    "    # Average the number of correct guesses (over the total samples)\n",
    "    return np.round(total_hits / len(only_best_beam), 4)\n",
    "\n",
    "\n",
    "def APL(true_best_pwr, est_best_pwr):\n",
    "\n",
    "    \n",
    "    return np.mean(10 * np.log10(est_best_pwr / true_best_pwr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "core_path = r'C:\\Python\\BeamPrediction_DeepLearning\\BeamPrediction_DeepLearning\\data'\n",
    "\n",
    "scen_idx = 36\n",
    "training_path ='deepsense_challenge2023_trainset.csv'\n",
    "testing_path = 'deepsense_challenge2023_testset_example'\n",
    "csv_train = os.path.join(core_path, training_path)\n",
    "csv_dict_path = os.path.join(core_path, 'scenario36.p')\n",
    "\n",
    "X_SIZE = 5\n",
    "N_GPS = 2\n",
    "N_GPS_COORD = 2\n",
    "N_ARR = 4\n",
    "N_BEAMS = 64\n",
    "IDX_COL1 = 'unique_index'\n",
    "IDX_COL2 = 'abs_index'\n",
    "\n",
    "# Carregar dados\n",
    "with open(csv_dict_path, 'rb') as fp:\n",
    "    csv_dict = pickle.load(fp)\n",
    "\n",
    "df_train = pd.read_csv(csv_train)\n",
    "\n",
    "if True:  # TREINAMENTO\n",
    "    # try:\n",
    "        # Preparar os dados\n",
    "        samples_of_scen = np.where(df_train['scenario'] == scen_idx)[0][1000:23187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22187,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_of_scen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA está disponível. Utilizando GPU: NVIDIA GeForce RTX 3050 6GB Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Verificar se CUDA está disponível\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"CUDA está disponível. Utilizando GPU:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA não está disponível. Utilizando CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0+cu118\n",
      "11.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.version.cuda)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>x1_unique_index</th>\n",
       "      <th>x1_unit1_gps1</th>\n",
       "      <th>x1_unit2_gps1</th>\n",
       "      <th>x1_unit1_rgb5</th>\n",
       "      <th>x1_unit1_rgb6</th>\n",
       "      <th>x2_unique_index</th>\n",
       "      <th>x2_unit1_gps1</th>\n",
       "      <th>x2_unit2_gps1</th>\n",
       "      <th>x2_unit1_rgb5</th>\n",
       "      <th>...</th>\n",
       "      <th>x5_unit1_gps1</th>\n",
       "      <th>x5_unit2_gps1</th>\n",
       "      <th>x5_unit1_rgb5</th>\n",
       "      <th>x5_unit1_rgb6</th>\n",
       "      <th>y1_unique_index</th>\n",
       "      <th>y1_unit1_overall-beam</th>\n",
       "      <th>y1_unit1_pwr1</th>\n",
       "      <th>y1_unit1_pwr2</th>\n",
       "      <th>y1_unit1_pwr3</th>\n",
       "      <th>y1_unit1_pwr4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>2674</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8869_11-46-31.233334...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33301_11-46-31.25000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.205818.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.205818.jpg</td>\n",
       "      <td>2676</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8871_11-46-31.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33303_11-46-31.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.406020.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8877_11-46-32.000000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33310_11-46-32.00000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.006626.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.006626.jpg</td>\n",
       "      <td>2687</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-31.859441.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>2675</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8870_11-46-31.300000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33302_11-46-31.33333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.305919.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.305919.jpg</td>\n",
       "      <td>2677</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8872_11-46-31.500000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33304_11-46-31.50000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.506121.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8879_11-46-32.133334...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33311_11-46-32.08333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.106727.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.106727.jpg</td>\n",
       "      <td>2688</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-31.959645.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>2676</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8871_11-46-31.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33303_11-46-31.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.406020.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.406020.jpg</td>\n",
       "      <td>2678</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8873_11-46-31.600000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33305_11-46-31.58333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.606222.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8880_11-46-32.200000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33313_11-46-32.25000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.206828.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.206828.jpg</td>\n",
       "      <td>2689</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.059402.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>2677</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8872_11-46-31.500000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33304_11-46-31.50000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.506121.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.506121.jpg</td>\n",
       "      <td>2679</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8874_11-46-31.700000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33307_11-46-31.75000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.706323.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8881_11-46-32.300000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33314_11-46-32.33333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.306929.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.306929.jpg</td>\n",
       "      <td>2690</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.160005.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2678</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8873_11-46-31.600000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33305_11-46-31.58333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.606222.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.606222.jpg</td>\n",
       "      <td>2680</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8875_11-46-31.800000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33308_11-46-31.83333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.806424.jpg</td>\n",
       "      <td>...</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8882_11-46-32.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33315_11-46-32.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.407030.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.407030.jpg</td>\n",
       "      <td>2691</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.260057.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario  x1_unique_index  \\\n",
       "0        36             2674   \n",
       "1        36             2675   \n",
       "2        36             2676   \n",
       "3        36             2677   \n",
       "4        36             2678   \n",
       "\n",
       "                                       x1_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8869_11-46-31.233334...   \n",
       "1  scenario36/unit1/gps1/gps_8870_11-46-31.300000...   \n",
       "2  scenario36/unit1/gps1/gps_8871_11-46-31.400000...   \n",
       "3  scenario36/unit1/gps1/gps_8872_11-46-31.500000...   \n",
       "4  scenario36/unit1/gps1/gps_8873_11-46-31.600000...   \n",
       "\n",
       "                                       x1_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33301_11-46-31.25000...   \n",
       "1  scenario36/unit2/gps1/gps_33302_11-46-31.33333...   \n",
       "2  scenario36/unit2/gps1/gps_33303_11-46-31.41666...   \n",
       "3  scenario36/unit2/gps1/gps_33304_11-46-31.50000...   \n",
       "4  scenario36/unit2/gps1/gps_33305_11-46-31.58333...   \n",
       "\n",
       "                                     x1_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.205818.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.305919.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-31.406020.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-31.506121.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-31.606222.jpg   \n",
       "\n",
       "                                     x1_unit1_rgb6  x2_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-31.205818.jpg             2676   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-31.305919.jpg             2677   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-31.406020.jpg             2678   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-31.506121.jpg             2679   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-31.606222.jpg             2680   \n",
       "\n",
       "                                       x2_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8871_11-46-31.400000...   \n",
       "1  scenario36/unit1/gps1/gps_8872_11-46-31.500000...   \n",
       "2  scenario36/unit1/gps1/gps_8873_11-46-31.600000...   \n",
       "3  scenario36/unit1/gps1/gps_8874_11-46-31.700000...   \n",
       "4  scenario36/unit1/gps1/gps_8875_11-46-31.800000...   \n",
       "\n",
       "                                       x2_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33303_11-46-31.41666...   \n",
       "1  scenario36/unit2/gps1/gps_33304_11-46-31.50000...   \n",
       "2  scenario36/unit2/gps1/gps_33305_11-46-31.58333...   \n",
       "3  scenario36/unit2/gps1/gps_33307_11-46-31.75000...   \n",
       "4  scenario36/unit2/gps1/gps_33308_11-46-31.83333...   \n",
       "\n",
       "                                     x2_unit1_rgb5  ...  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.406020.jpg  ...   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.506121.jpg  ...   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-31.606222.jpg  ...   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-31.706323.jpg  ...   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-31.806424.jpg  ...   \n",
       "\n",
       "                                       x5_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8877_11-46-32.000000...   \n",
       "1  scenario36/unit1/gps1/gps_8879_11-46-32.133334...   \n",
       "2  scenario36/unit1/gps1/gps_8880_11-46-32.200000...   \n",
       "3  scenario36/unit1/gps1/gps_8881_11-46-32.300000...   \n",
       "4  scenario36/unit1/gps1/gps_8882_11-46-32.400000...   \n",
       "\n",
       "                                       x5_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33310_11-46-32.00000...   \n",
       "1  scenario36/unit2/gps1/gps_33311_11-46-32.08333...   \n",
       "2  scenario36/unit2/gps1/gps_33313_11-46-32.25000...   \n",
       "3  scenario36/unit2/gps1/gps_33314_11-46-32.33333...   \n",
       "4  scenario36/unit2/gps1/gps_33315_11-46-32.41666...   \n",
       "\n",
       "                                     x5_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-32.006626.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-32.106727.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-32.206828.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-32.306929.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-32.407030.jpg   \n",
       "\n",
       "                                     x5_unit1_rgb6 y1_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-32.006626.jpg            2687   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-32.106727.jpg            2688   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-32.206828.jpg            2689   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-32.306929.jpg            2690   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-32.407030.jpg            2691   \n",
       "\n",
       "  y1_unit1_overall-beam                                  y1_unit1_pwr1  \\\n",
       "0                   161  scenario36/unit1/pwr1/pwr_11-46-31.859441.txt   \n",
       "1                   161  scenario36/unit1/pwr1/pwr_11-46-31.959645.txt   \n",
       "2                   161  scenario36/unit1/pwr1/pwr_11-46-32.059402.txt   \n",
       "3                   161  scenario36/unit1/pwr1/pwr_11-46-32.160005.txt   \n",
       "4                   161  scenario36/unit1/pwr1/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr2  \\\n",
       "0  scenario36/unit1/pwr2/pwr_11-46-31.859441.txt   \n",
       "1  scenario36/unit1/pwr2/pwr_11-46-31.959645.txt   \n",
       "2  scenario36/unit1/pwr2/pwr_11-46-32.059402.txt   \n",
       "3  scenario36/unit1/pwr2/pwr_11-46-32.160005.txt   \n",
       "4  scenario36/unit1/pwr2/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr3  \\\n",
       "0  scenario36/unit1/pwr3/pwr_11-46-31.859441.txt   \n",
       "1  scenario36/unit1/pwr3/pwr_11-46-31.959645.txt   \n",
       "2  scenario36/unit1/pwr3/pwr_11-46-32.059402.txt   \n",
       "3  scenario36/unit1/pwr3/pwr_11-46-32.160005.txt   \n",
       "4  scenario36/unit1/pwr3/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr4  \n",
       "0  scenario36/unit1/pwr4/pwr_11-46-31.859441.txt  \n",
       "1  scenario36/unit1/pwr4/pwr_11-46-31.959645.txt  \n",
       "2  scenario36/unit1/pwr4/pwr_11-46-32.059402.txt  \n",
       "3  scenario36/unit1/pwr4/pwr_11-46-32.160005.txt  \n",
       "4  scenario36/unit1/pwr4/pwr_11-46-32.260057.txt  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "scen_idx = 36\n",
    "csv_train = r'C:\\Python\\BeamPrediction_DeepLearning\\BeamPrediction_DeepLearning\\data\\deepsense_challenge2023_trainset.csv'\n",
    "csv_dict_path = rf'C:\\Python\\BeamPrediction_DeepLearning\\BeamPrediction_DeepLearning\\data\\scenario36.p'\n",
    "\n",
    "with open(csv_dict_path, 'rb') as fp:\n",
    "    csv_dict = pickle.load(fp)\n",
    "\n",
    "df_train = pd.read_csv(csv_train)\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 23187/23187 [00:26<00:00, 886.63it/s] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load all positions\n",
    "samples_of_scen = np.where(df_train['scenario'] == scen_idx)[0]\n",
    "n_samples = len(samples_of_scen)\n",
    "\n",
    "X_SIZE = 5      # 5 input samples\n",
    "N_GPS = 2       # 2 GPSs (unit1 and unit2)\n",
    "N_GPS_COORD = 2 # 2 GPS coords (latitude & longitude)\n",
    "N_ARR = 4       # 4 arrays\n",
    "N_BEAMS = 64    # 64 beams per array\n",
    "IDX_COL1 = 'unique_index' # index col in the training CSV\n",
    "IDX_COL2 = 'abs_index'    # index col in the CSVs of the V2V dataset \n",
    "                          # this indices are the same, just dif names\n",
    "loaded_positions = set()\n",
    "train_positions = np.zeros((n_samples, X_SIZE, N_GPS, N_GPS_COORD))\n",
    "y_pos1 = np.zeros((n_samples, N_GPS_COORD))\n",
    "y_pos2 = np.zeros((n_samples, N_GPS_COORD))\n",
    "y_pwrs = np.zeros((n_samples, N_ARR, N_BEAMS))\n",
    "\n",
    "# Loop over each sample in the training data\n",
    "for sample_idx in tqdm(range(n_samples), desc='Loading data'):\n",
    "    # Get the current training sample\n",
    "    train_sample = samples_of_scen[sample_idx]\n",
    "    \n",
    "    # Loop over each position index on the X axis\n",
    "    for x_idx in range(X_SIZE):\n",
    "        # Find the absolute relative index in the CSV DataFrame for the current training sample\n",
    "        abs_idx_relative_index = (csv_dict[IDX_COL2] == df_train[f'x{x_idx+1}_'+IDX_COL1][train_sample])\n",
    "        \n",
    "        # Fill the training positions for the current sample and current X index\n",
    "        # GPS positions of 'unit1' and 'unit2' are stored in train_positions\n",
    "        # Index [0, :] is used for 'unit1' GPS coordinates, and index [1, :] is used for 'unit2' GPS coordinates\n",
    "        train_positions[sample_idx, x_idx, 0, :] = csv_dict['unit1_gps1'][abs_idx_relative_index]\n",
    "        train_positions[sample_idx, x_idx, 1, :] = csv_dict['unit2_gps1'][abs_idx_relative_index]\n",
    "\n",
    "    # Find the index for the ground truth position 'y' in the CSV dictionary DataFrame\n",
    "    y_idx = (csv_dict[IDX_COL2] == df_train['y1_'+IDX_COL1][train_sample])\n",
    "\n",
    "    # Store the GPS positions for 'unit1' and 'unit2' corresponding to the ground truth 'y' position\n",
    "    y_pos1[sample_idx] = csv_dict['unit1_gps1'][y_idx]\n",
    "    y_pos2[sample_idx] = csv_dict['unit2_gps1'][y_idx]\n",
    "\n",
    "    # Loop over each antenna array to store the power readings corresponding to the ground truth 'y' position\n",
    "    for arr_idx in range(N_ARR):\n",
    "        y_pwrs[sample_idx, arr_idx] = csv_dict[f'unit1_pwr{arr_idx+1}'][y_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23187, 5, 2, 2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23187, 2), (23187, 2), (23187, 4, 64))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pos2.shape , y_pos1.shape , y_pwrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ground truth beams for 'unit1' from the DataFrame, based on the selected samples\n",
    "y_true_beams = df_train['y1_unit1_overall-beam'].values[samples_of_scen] \n",
    "\n",
    "y_pwrs_reshaped = y_pwrs.reshape((n_samples, -1)) # (23187, 256)\n",
    "# Sort the power readings in descending order to get the indices of the beams with highest power\n",
    "all_true_beams = np.flip(np.argsort(y_pwrs_reshaped, axis=1), axis=1) # (23187, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23187, 256), (23187, 256))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_true_beams.shape, y_pwrs_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(64)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(128)\n",
    "        self.fc1 = nn.Linear(128 * input_size, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, 2)  # Saída para as posições latitudinal e longitudinal\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.batch_norm1(x)\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = self.batch_norm2(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def train_cnn(input_positions, delta_input, delta_output, epochs=7):\n",
    "    n_samples = input_positions.shape[0]\n",
    "    x_size = input_positions.shape[1]\n",
    "    \n",
    "    # Preparando os dados de entrada e saída\n",
    "    X_train = torch.zeros((n_samples, 1, x_size)).to(device)\n",
    "    y_train = torch.zeros((n_samples, 2)).to(device)\n",
    "    \n",
    "    for sample_idx in range(n_samples):\n",
    "        input_pos = input_positions[sample_idx]\n",
    "        X_train[sample_idx, 0, :] = torch.tensor(input_pos[:, 0], dtype=torch.float32)  # Usando apenas a primeira coluna como entrada\n",
    "        y_train[sample_idx, 0] = input_pos[-1, 0] + delta_output  # Prevendo a posição latitudinal\n",
    "        y_train[sample_idx, 1] = input_pos[-1, 1] + delta_output  # Prevendo a posição longitudinal\n",
    "    \n",
    "    model = CNN(x_size).to(device)\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Treinando o modelo\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i in range(n_samples):\n",
    "            inputs, labels = X_train[i:i+1], y_train[i:i+1]\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {running_loss / n_samples}')\n",
    "    \n",
    "    return model\n",
    "def estimate_positions(input_positions, delta_input, delta_output, model, device='cuda'):\n",
    "    n_samples = input_positions.shape[0]\n",
    "    out_pos = np.zeros((n_samples, 2))\n",
    "\n",
    "    x_size = input_positions.shape[1]\n",
    "    time_steps = delta_input * np.arange(x_size)  # Vetor de tempo para as entradas\n",
    "    model.eval()  # Coloca o modelo em modo de avaliação (desativa o dropout e outras camadas específicas de treino)\n",
    "\n",
    "    # Itera sobre cada amostra para estimar a posição correspondente\n",
    "    for sample_idx in tqdm(range(n_samples), desc='Estimating input positions'):\n",
    "        input_pos = input_positions[sample_idx]\n",
    "\n",
    "        # Ajusta o tempo final, considerando o delta_output\n",
    "        final_time = time_steps[-1] + delta_output\n",
    "\n",
    "        # Converte a entrada para um tensor PyTorch e move para o dispositivo especificado (CPU ou GPU)\n",
    "        inputs = torch.tensor(input_pos[:, 0], dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "        \n",
    "        # Gera a previsão utilizando o modelo\n",
    "        prediction = model(inputs)\n",
    "        \n",
    "        # Move a previsão para a CPU e converte para um array numpy\n",
    "        out_pos[sample_idx, :] = prediction.detach().cpu().numpy().flatten()\n",
    "\n",
    "        # Ajusta as previsões com base no delta_output\n",
    "        out_pos[sample_idx, 0] += delta_output * (final_time / time_steps[-1])\n",
    "        out_pos[sample_idx, 1] += delta_output * (final_time / time_steps[-1])\n",
    "    return out_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "182.5748031496063"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "23187/127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 5.421092167829156\n",
      "Epoch 2/10, Loss: 0.02108592308545671\n",
      "Epoch 3/10, Loss: 0.017169468211169284\n",
      "Epoch 4/10, Loss: 0.014229267681605373\n",
      "Epoch 5/10, Loss: 0.011956779434614326\n",
      "Epoch 6/10, Loss: 0.01035710670814596\n",
      "Epoch 7/10, Loss: 0.009612457495696817\n",
      "Epoch 8/10, Loss: 0.008819554514616676\n",
      "Epoch 9/10, Loss: 0.00836262059705557\n",
      "Epoch 10/10, Loss: 0.007928254043348688\n",
      "Epoch 1/10, Loss: 5.493330075519753\n",
      "Epoch 2/10, Loss: 0.019920901618520847\n",
      "Epoch 3/10, Loss: 0.016005033919209325\n",
      "Epoch 4/10, Loss: 0.014795476926540384\n",
      "Epoch 5/10, Loss: 0.011913913147312933\n",
      "Epoch 6/10, Loss: 0.010835539775753232\n",
      "Epoch 7/10, Loss: 0.010159822324818315\n",
      "Epoch 8/10, Loss: 0.009327660252826116\n",
      "Epoch 9/10, Loss: 0.008418735177687998\n",
      "Epoch 10/10, Loss: 0.007808831440177686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating input positions: 100%|██████████| 23187/23187 [00:32<00:00, 719.99it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando modelo 2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating input positions: 100%|██████████| 23187/23187 [00:32<00:00, 708.60it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "delta_input = 0.2  # time difference between input samples [s]\n",
    "delta_output = 0.5  # time difference from last input to output [s]\n",
    "model_1 = train_cnn(train_positions[:, :, 0, :], delta_input, delta_output)\n",
    "print('Treinando modelo 2 \\n')\n",
    "model_2 = train_cnn(train_positions[:, :, 1, :], delta_input, delta_output)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps1_est_pos = estimate_positions(train_positions[:, :, 0, :], delta_input, delta_output,model_1)\n",
    "gps2_est_pos = estimate_positions(train_positions[:, :, 1, :], delta_input, delta_output, model_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 28.72099304, -90.89217377],\n",
       "       [ 28.72099304, -90.89217377],\n",
       "       [ 28.72099304, -90.89217377],\n",
       "       ...,\n",
       "       [ 28.69013596, -90.79010773],\n",
       "       [ 28.69013214, -90.79010773],\n",
       "       [ 28.69013596, -90.79010773]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps1_est_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23187, 5, 2), (23187, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_positions[:, :, 0, :].shape , gps1_est_pos.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "lat_deltas = gps1_est_pos[:, 0] - train_positions[:, -1, 0, 0]\n",
    "lon_deltas = gps1_est_pos[:, 1] - train_positions[:, -1, 0, 1]\n",
    "\n",
    "# Compute the orientation (heading) based on the position deltas\n",
    "heading = compute_ori_from_pos_delta(lat_deltas, lon_deltas)\n",
    "# 2.2 - Determine relative position (converted to orientation) between vehicles\n",
    "# Calculate the difference in latitude and longitude between the estimated GPS positions of vehicle 1 anp´pppd vehicle 2\n",
    "lat_deltas = gps1_est_pos[:, 0] - gps2_est_pos[:, 0]\n",
    "lon_deltas = gps1_est_pos[:, 1] - gps2_est_pos[:, 1]\n",
    "# Compute the orientation (relative position) based on the position deltas\n",
    "ori_rel = compute_ori_from_pos_delta(lat_deltas, lon_deltas)\n",
    "\n",
    "# Compute the estimated Angle of Arrival (AOA) using the relative orientation, heading, and a reference angle\n",
    "# The relative orientation is subtracted from the heading and a constant angle (pi/4) is subtracted from the result\n",
    "aoa_estimation = norm_2pi(-1 * (ori_rel - heading - np.pi / 4))\n",
    "\n",
    "# Chep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_beam_uniformly_from_aoa(aoa):\n",
    "\n",
    "    # Convert input to PyTorch tensor\n",
    "    beam_predictions = np.zeros_like(aoa)\n",
    "\n",
    "    beam_ori = np.arange(N_BEAMS * N_ARR) / (N_BEAMS * N_ARR - 1) * 2*np.pi - np.pi\n",
    "\n",
    "    angl_diff_to_each_beam = aoa.reshape((-1, 1)) - beam_ori\n",
    "\n",
    "    beam_predictions = np.argsort(abs(angl_diff_to_each_beam), axis=1)\n",
    "\n",
    "    return beam_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated_shift = 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "beam_pred_all = predict_beam_uniformly_from_aoa(aoa_estimation)\n",
    "best_beam_pred = np.copy(beam_pred_all[:, 0]) # keep decoupled\n",
    "\n",
    "# After analysis, we were often 1 beam short. \n",
    "pred_diff = np.array([circular_distance(a, b, sign=True)\n",
    "                      for a, b in zip(best_beam_pred, y_true_beams)])\n",
    "\n",
    "# The box sometimes is slightly rotated around it's Z axis, so we can shift our\n",
    "# Beam predictions a constant offset to get better performance. Admit offsets up to 2.\n",
    "# Note: this adjustment is only for the training phase\n",
    "shift = -round(np.mean(pred_diff[abs(pred_diff) < 5]))\n",
    "print(f'estimated_shift = {shift}')\n",
    "beam_pred_all += shift\n",
    "best_beam_pred += shift\n",
    "\n",
    "# make sure the output is within 0-255\n",
    "beam_pred_all[beam_pred_all>255] -= 255\n",
    "beam_pred_all[beam_pred_all<0] += 255\n",
    "best_beam_pred[best_beam_pred>255] -= 255\n",
    "best_beam_pred[best_beam_pred<0] += 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Beam Index Distance = 48.40\n"
     ]
    }
   ],
   "source": [
    "pred_diff_abs = np.array([circular_distance(a, b)\n",
    "                          for a, b in zip(best_beam_pred, all_true_beams[:,0])])\n",
    "average_beam_index_diff = np.mean(pred_diff_abs) # lower is better!\n",
    "\n",
    "print(f'Average Beam Index Distance = {average_beam_index_diff:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-k = [0.125  0.3642 0.4202]\n",
      "(not used) Top-k = [0.125  0.3688 0.4357]\n",
      "Average Power Loss = -10.93 dB\n"
     ]
    }
   ],
   "source": [
    "# \"Probability of the prediction of the best beam being in the set of best k ground truth beams\"\n",
    "top_k = compute_acc(all_true_beams, best_beam_pred, top_k=[1, 3, 5])\n",
    "print(f'Top-k = {top_k}')\n",
    "\n",
    "# \"Probability of the ground truth best beam being in the set of most likely k predicted beams\"\n",
    "top_k = compute_acc(beam_pred_all, all_true_beams[:, 0], top_k=[1, 3, 5])\n",
    "print(f'(not used) Top-k = {top_k}')\n",
    "\n",
    "# For practical submissions, we implement only the first way so we \n",
    "# only require the best predicted beam. \n",
    "\n",
    "# And finally, the score -> APL (Average Power Loss)\n",
    "est_best_pwr = y_pwrs_reshaped[np.arange(n_samples), best_beam_pred]\n",
    "true_best_pwr = y_pwrs_reshaped[np.arange(n_samples), all_true_beams[:, 0]]\n",
    "apl = APL(true_best_pwr, est_best_pwr)\n",
    "print(f'Average Power Loss = {apl:.2f} dB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
