{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Jun  9 08:17:57 2023\n",
    "\n",
    "@author: Joao\n",
    "\n",
    "This script reads a training CSV, outputs predictions for the data, and applies\n",
    "the score metric to compute the final score. \n",
    "\n",
    "It also computes a few other known metrics, like top-k accuracy and average power loss.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 'F5' Começa a debuger o codigo \n",
    "# 'F10' Analisar a linha sem entrar no codigo \n",
    "# 'F11' Analisar linha  e entrar no codigo \n",
    "# 'SHIFT-F11' sair do bloco de codigo atual e continuar a execução\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from tqdm import tqdm\n",
    "\n",
    "X_SIZE = 5      # 5 input samples\n",
    "N_GPS = 2       # 2 GPSs (unit1 and unit2)\n",
    "N_GPS_COORD = 2 # 2 GPS coords (latitude & longitude)\n",
    "N_ARR = 4       # 4 arrays\n",
    "N_BEAMS = 64    # 64 beams per array\n",
    "IDX_COL1 = 'unique_index' # index col in the training CSV\n",
    "IDX_COL2 = 'abs_index'    # index col in the CSVs of the V2V dataset \n",
    "                          # this indices are the same, just dif names\n",
    "\n",
    "def norm_2pi(x):\n",
    "    \"\"\"\n",
    "    Normalize angles in radians to the range of -pi to pi.\n",
    "\n",
    "    Parameters:\n",
    "    - x (numpy.ndarray or array-like): Input angles in radians.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Angles normalized to the range of -pi to pi.\n",
    "\n",
    "    The function takes an array of angles in radians and normalizes them to the\n",
    "    range of -pi to pi. It handles values outside this range by applying modular\n",
    "    arithmetic to bring them within the specified range.\n",
    "\n",
    "    Examples:\n",
    "    >>> import numpy as np\n",
    "    >>> angles = np.array([-3*np.pi, 2*np.pi, np.pi/2])\n",
    "    >>> norm_2pi(angles)\n",
    "    array([ 3.14159265, -3.14159265,  1.57079633])\n",
    "\n",
    "    Note:\n",
    "    The function uses modular arithmetic to ensure the normalized angles lie\n",
    "    within the range of -pi to pi. If an angle is less than -pi after\n",
    "    normalization, a warning message is printed.\n",
    "    \"\"\"\n",
    "    # -pi to pi\n",
    "    x_normed = np.empty_like(x)\n",
    "    x_normed[:] = x\n",
    "    for i in range(len(x)):\n",
    "        if abs(x[i]) >= np.pi:\n",
    "            x_normed[i] = x[i] % (2*np.pi)\n",
    "\n",
    "            if x[i] >= np.pi:\n",
    "                x_normed[i] -= 2*np.pi\n",
    "\n",
    "        while x_normed[i] < -np.pi:\n",
    "            x_normed[i] += 2*np.pi\n",
    "\n",
    "        while x_normed[i] > np.pi:\n",
    "            x_normed[i] -= 2*np.pi\n",
    "\n",
    "        if x_normed[i] < -np.pi:\n",
    "            print(f'{i}, {x_normed[i]}')\n",
    "\n",
    "    return x_normed\n",
    "\n",
    "\n",
    "def compute_ori_from_pos_delta(lat_deltas, lon_deltas):\n",
    "    \"\"\"\n",
    "    Compute orientation in the range [-pi, pi].\n",
    "\n",
    "    Parameters:\n",
    "    - lat_deltas (numpy.ndarray or array-like): Differences in latitudes.\n",
    "    - lon_deltas (numpy.ndarray or array-like): Differences in longitudes.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Orientations corresponding to the differences in latitudes and longitudes.\n",
    "\n",
    "    The function computes orientation based on differences in latitudes and longitudes.\n",
    "    The orientation is given in radians and falls within the range of -pi to pi.\n",
    "    The orientation is calculated using arctan(delta_lat / delta_lon).\n",
    "    If delta_lon is 0, the orientation is determined based on the sign of delta_lat.\n",
    "\n",
    "    Thresholds:\n",
    "    If delta_lat is below a certain threshold (thres_lat), it is considered as 0.\n",
    "\n",
    "    If lat_deltas and lon_deltas are N x 2, the function computes the difference\n",
    "    between the two columns.\n",
    "    If lat_deltas and lon_deltas are N x 1, it computes differences in consecutive samples\n",
    "    (uses two positions at different times to get orientation).\n",
    "\n",
    "\n",
    "    Examples:\n",
    "    >>> import numpy as np\n",
    "    >>> lat_deltas = np.array([0, 1, -1, 0])\n",
    "    >>> lon_deltas = np.array([1, 0, 0, -1])\n",
    "    >>> compute_ori_from_pos_delta(lat_deltas, lon_deltas)\n",
    "    array([ 0.        ,  1.57079633, -1.57079633,  3.14159265])\n",
    "\n",
    "    \"\"\"\n",
    "    n_samples = len(lat_deltas)\n",
    "    pose = np.zeros(n_samples)\n",
    "\n",
    "    for i in range(n_samples):\n",
    "\n",
    "        delta_lat = lat_deltas[i-1]\n",
    "        delta_lon = lon_deltas[i-1]\n",
    "\n",
    "        if delta_lon == 0:\n",
    "            if delta_lat == 0:\n",
    "                pose[i] = 0\n",
    "                continue\n",
    "            elif delta_lat > 0:\n",
    "                slope = np.pi / 2\n",
    "            elif delta_lat < 0:\n",
    "                slope = -np.pi / 2\n",
    "        else:\n",
    "            slope = np.arctan(delta_lat / delta_lon)\n",
    "            if delta_lat == 0:\n",
    "                slope = np.pi if delta_lon < 0 else 0\n",
    "            elif delta_lat < 0 and delta_lon < 0:\n",
    "                slope = -np.pi + slope\n",
    "            elif delta_lon < 0 and delta_lat > 0:\n",
    "                slope = np.pi + slope\n",
    "\n",
    "        pose[i] = slope\n",
    "\n",
    "    return pose\n",
    "\n",
    "\n",
    "def estimate_positions(input_positions, delta_input, delta_output):\n",
    "    \"\"\"\n",
    "    Estimate positions based on input positions using linear interpolation.\n",
    "\n",
    "    Parameters:\n",
    "    - input_positions (numpy.ndarray): Input positions with shape (n_samples, n_points, 2).\n",
    "    - delta_input (float): Time difference between consecutive input samples.\n",
    "    - delta_output (float): Time difference for the desired output position.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Estimated output positions with shape (n_samples, 2).\n",
    "\n",
    "    The function estimates output positions based on input positions using linear interpolation.\n",
    "    It assumes that input positions are provided at regular intervals with a specified time difference (delta_input).\n",
    "    The output positions are estimated at a future time (delta_output) using linear interpolation.\n",
    "\n",
    "    Examples:\n",
    "    >>> input_positions = np.array([[[1.0, 2.0], [2.0, 3.0], [3.0, 4.0]],\n",
    "    ...                              [[4.0, 5.0], [5.0, 6.0], [6.0, 7.0]]])\n",
    "    >>> delta_input = 1.0\n",
    "    >>> delta_output = 2.0\n",
    "    >>> estimate_positions(input_positions, delta_input, delta_output)\n",
    "    array([[ 5.,  6.],\n",
    "           [10., 11.]])\n",
    "\n",
    "    Note:\n",
    "    - The input_positions array should have shape (n_samples, n_points, 2), where n_samples is the number of samples,\n",
    "      n_points is the number of input points, and the last dimension represents the (latitude, longitude) coordinates.\n",
    "    - The function uses linear interpolation to estimate the positions at a future time (delta_output).\n",
    "    \"\"\"\n",
    "\n",
    "        # Calculate the number of samples in the input positions array\n",
    "    n_samples = input_positions.shape[0]\n",
    "\n",
    "    # Initialize an array to store the estimated output positions\n",
    "    out_pos = np.zeros((n_samples, 2))\n",
    "\n",
    "    # Determine the size of each input position array (number of samples)\n",
    "    x_size = input_positions.shape[1]\n",
    "\n",
    "    # Define the time points corresponding to each sample in the input positions array\n",
    "    x = delta_input * np.arange(x_size)\n",
    "\n",
    "    # Iterate over each sample to estimate the corresponding output position\n",
    "    for sample_idx in tqdm(range(n_samples), desc='Estimating input positions'):\n",
    "        # Extract the input positions for the current sample\n",
    "        input_pos = input_positions[sample_idx]\n",
    "\n",
    "        # Perform linear interpolation to estimate latitude and longitude at the output time\n",
    "        f_lat = scipy.interpolate.interp1d(x, input_pos[:, 0], fill_value='extrapolate')\n",
    "        f_lon = scipy.interpolate.interp1d(x, input_pos[:, 1], fill_value='extrapolate')\n",
    "\n",
    "        # Calculate the estimated latitude and longitude at the output time\n",
    "        out_pos[sample_idx, 0] = f_lat(x[-1] + delta_output)\n",
    "        out_pos[sample_idx, 1] = f_lon(x[-1] + delta_output)\n",
    "\n",
    "    # Return the array of estimated output positions\n",
    "    return out_pos\n",
    "\n",
    "\n",
    "\n",
    "def predict_beam_uniformly_from_aoa(aoa):\n",
    "    \"\"\"\n",
    "    Predict beams uniformly based on the angles of arrival (AOA).\n",
    "\n",
    "    Parameters:\n",
    "    - aoa (numpy.ndarray or array-like): Angles of arrival with shape (N, 1),\n",
    "      where N is the number of datapoints.\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Ordered list of indices of the closest predictor points,\n",
    "      representing the predicted beams. Shape (N, K), where K is the total number\n",
    "      of beams.\n",
    "\n",
    "    The function computes the distance of each datapoint to each predictor point\n",
    "    based on the angles of arrival (AOA). It returns an ordered list of indices\n",
    "    representing the predicted beams for each datapoint.\n",
    "\n",
    "    Note:\n",
    "    - The input aoa should have shape (N, 1), where N is the number of datapoints.\n",
    "    - The function uses a uniformly distributed set of predictor points in the\n",
    "      range [-pi, pi] to compute the distance.\n",
    "    - The output is an array with shape (N, K), where K is the total number of beams.\n",
    "    - The indices in the output array represent the closest predictor points for each datapoint.\n",
    "\n",
    "    Examples:\n",
    "    >>> aoa = np.array([[0.1], [1.5], [-2.0]])\n",
    "    >>> predict_beam_uniformly_from_aoa(aoa)\n",
    "    array([[12, 13, 11, ...,  6,  7,  5],\n",
    "           [11, 12, 10, ...,  5,  6,  4],\n",
    "           [ 5,  6,  4, ..., 15,  0, 14]])\n",
    "\n",
    "    \"\"\"\n",
    "    beam_predictions = np.zeros_like(aoa)\n",
    "\n",
    "    beam_ori = np.arange(N_BEAMS * N_ARR) / (N_BEAMS * N_ARR - 1) * 2*np.pi - np.pi\n",
    "\n",
    "    angl_diff_to_each_beam = aoa.reshape((-1, 1)) - beam_ori\n",
    "\n",
    "    beam_predictions = np.argsort(abs(angl_diff_to_each_beam), axis=1)\n",
    "\n",
    "    return beam_predictions\n",
    "\n",
    "\n",
    "def circular_distance(a, b, l=256, sign=False):\n",
    "    \"\"\"\n",
    "    Compute the circular distance between two beam indices.\n",
    "\n",
    "    Parameters:\n",
    "    - a (int): First beam index.\n",
    "    - b (int): Second beam index.\n",
    "    - l (int, optional): Total number of beam indices in the circle (default is 256).\n",
    "    - sign (bool, optional): If True, considers a as predicted and b as truth (default is False).\n",
    "\n",
    "    Returns:\n",
    "    - int: Circular distance between the two beam indices.\n",
    "\n",
    "    The function computes the circular distance between two beam indices, a and b,\n",
    "    in a circular way. It considers all numbers written in a circle with 'l' numbers,\n",
    "    then computes the shortest distance between any two numbers.\n",
    "\n",
    "    Examples:\n",
    "    >>> circular_distance(0, 5, l=256)\n",
    "    5\n",
    "    >>> circular_distance(0, 255, l=256)\n",
    "    1\n",
    "    >>> circular_distance(0, 250, l=256)\n",
    "    6\n",
    "    >>> circular_distance(0, 127, l=256)\n",
    "    127\n",
    "\n",
    "    Note:\n",
    "    - If 'sign' is True, a is considered as predicted, and b as truth.\n",
    "    - The distance is returned as a positive value unless 'sign' is True.\n",
    "    \"\"\"\n",
    "    while a < 0:\n",
    "        a = l - abs(a)\n",
    "    while b < 0:\n",
    "        b = l - abs(b)\n",
    "        \n",
    "    a = a % l if a >= l else a\n",
    "    b = b % l if b >= l else b\n",
    "    \n",
    "    dist = a - b\n",
    "\n",
    "    if abs(dist) > l/2:\n",
    "        dist = l - abs(dist)\n",
    "\n",
    "    return dist if sign else abs(dist)\n",
    "\n",
    "\n",
    "def compute_acc(all_beams, only_best_beam, top_k=[1, 3, 5]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Compute top-k accuracy given predicted and ground truth labels.\n",
    "\n",
    "    Parameters:\n",
    "    - all_beams (numpy.ndarray): Predicted beams with shape (N_SAMPLES, N_BEAMS),\n",
    "      representing either ground truth beams sorted by receive power or predicted beams\n",
    "      sorted by algorithm's confidence.\n",
    "    - only_best_beam (numpy.ndarray): Ground truth or predicted optimal beam index with shape (N_SAMPLES, 1).\n",
    "    - top_k (list, optional): List of integers representing the top-k values for accuracy calculation (default is [1, 3, 5]).\n",
    "\n",
    "    Returns:\n",
    "    - numpy.ndarray: Top-k accuracy values.\n",
    "\n",
    "    The function computes top-k accuracy given predicted and ground truth labels.\n",
    "    It works bidirectionally, allowing it to handle cases where 'all_beams' can represent\n",
    "    either the ground truth beams sorted by receive power or the predicted beams sorted by\n",
    "    the algorithm's confidence of being the best.\n",
    "\n",
    "    Examples:\n",
    "    >>> all_beams = np.array([[1, 2, 3], [3, 2, 1], [2, 1, 3]])\n",
    "    >>> only_best_beam = np.array([[1], [2], [3]])\n",
    "    >>> compute_acc(all_beams, only_best_beam, top_k=[1, 3])\n",
    "    array([0.6667, 1.    ])\n",
    "\n",
    "    Note:\n",
    "    - 'all_beams' is assumed to have shape (N_SAMPLES, N_BEAMS), where N_SAMPLES is the number of samples,\n",
    "      and N_BEAMS is the number of beams.\n",
    "    - 'only_best_beam' is assumed to have shape (N_SAMPLES, 1), representing either the ground truth or predicted optimal beam index.\n",
    "    - 'top_k' is a list of integers specifying the top-k values for accuracy calculation.\n",
    "    \"\"\"\n",
    "    n_top_k = len(top_k)\n",
    "    total_hits = np.zeros(n_top_k)\n",
    "\n",
    "    n_test_samples = len(only_best_beam)\n",
    "    if len(all_beams) != n_test_samples:\n",
    "        raise Exception(\n",
    "            'Number of predicted beams does not match number of labels.')\n",
    "\n",
    "    # For each test sample, count times where true beam is in k top guesses\n",
    "    for samp_idx in range(len(only_best_beam)):\n",
    "        for k_idx in range(n_top_k):\n",
    "            hit = np.any(all_beams[samp_idx, :top_k[k_idx]] == only_best_beam[samp_idx])\n",
    "            total_hits[k_idx] += 1 if hit else 0\n",
    "\n",
    "    # Average the number of correct guesses (over the total samples)\n",
    "    return np.round(total_hits / len(only_best_beam), 4)\n",
    "\n",
    "\n",
    "def APL(true_best_pwr, est_best_pwr):\n",
    "    \"\"\"\n",
    "    Calculate the Average Power Loss (APL).\n",
    "\n",
    "    Parameters:\n",
    "    - true_best_pwr (numpy.ndarray): True best power values.\n",
    "    - est_best_pwr (numpy.ndarray): Estimated best power values.\n",
    "\n",
    "    Returns:\n",
    "    - float: Average Power Loss.\n",
    "\n",
    "    The function computes the average of the power wasted by using the predicted beam\n",
    "    instead of the ground truth optimum beam.\n",
    "\n",
    "    Examples:\n",
    "    >>> true_best_pwr = np.array([1.0, 2.0, 3.0])\n",
    "    >>> est_best_pwr = np.array([1.5, 2.5, 3.5])\n",
    "    >>> APL(true_best_pwr, est_best_pwr)\n",
    "    0.1761\n",
    "\n",
    "    Note:\n",
    "    - 'true_best_pwr' and 'est_best_pwr' should have the same shape.\n",
    "    - The Average Power Loss is calculated as the average of 10 * log10(est_best_pwr / true_best_pwr).\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.mean(10 * np.log10(est_best_pwr / true_best_pwr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scenario</th>\n",
       "      <th>x1_unique_index</th>\n",
       "      <th>x1_unit1_gps1</th>\n",
       "      <th>x1_unit2_gps1</th>\n",
       "      <th>x1_unit1_rgb5</th>\n",
       "      <th>x1_unit1_rgb6</th>\n",
       "      <th>x2_unique_index</th>\n",
       "      <th>x2_unit1_gps1</th>\n",
       "      <th>x2_unit2_gps1</th>\n",
       "      <th>x2_unit1_rgb5</th>\n",
       "      <th>x2_unit1_rgb6</th>\n",
       "      <th>x3_unique_index</th>\n",
       "      <th>x3_unit1_gps1</th>\n",
       "      <th>x3_unit2_gps1</th>\n",
       "      <th>x3_unit1_rgb5</th>\n",
       "      <th>x3_unit1_rgb6</th>\n",
       "      <th>x4_unique_index</th>\n",
       "      <th>x4_unit1_gps1</th>\n",
       "      <th>x4_unit2_gps1</th>\n",
       "      <th>x4_unit1_rgb5</th>\n",
       "      <th>x4_unit1_rgb6</th>\n",
       "      <th>x5_unique_index</th>\n",
       "      <th>x5_unit1_gps1</th>\n",
       "      <th>x5_unit2_gps1</th>\n",
       "      <th>x5_unit1_rgb5</th>\n",
       "      <th>x5_unit1_rgb6</th>\n",
       "      <th>y1_unique_index</th>\n",
       "      <th>y1_unit1_overall-beam</th>\n",
       "      <th>y1_unit1_pwr1</th>\n",
       "      <th>y1_unit1_pwr2</th>\n",
       "      <th>y1_unit1_pwr3</th>\n",
       "      <th>y1_unit1_pwr4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>2674</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8869_11-46-31.233334...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33301_11-46-31.25000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.205818.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.205818.jpg</td>\n",
       "      <td>2676</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8871_11-46-31.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33303_11-46-31.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.406020.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.406020.jpg</td>\n",
       "      <td>2678</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8873_11-46-31.600000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33305_11-46-31.58333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.606222.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.606222.jpg</td>\n",
       "      <td>2680</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8875_11-46-31.800000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33308_11-46-31.83333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.806424.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.806424.jpg</td>\n",
       "      <td>2682</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8877_11-46-32.000000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33310_11-46-32.00000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.006626.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.006626.jpg</td>\n",
       "      <td>2687</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-31.859441.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-31.859441.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>2675</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8870_11-46-31.300000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33302_11-46-31.33333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.305919.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.305919.jpg</td>\n",
       "      <td>2677</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8872_11-46-31.500000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33304_11-46-31.50000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.506121.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.506121.jpg</td>\n",
       "      <td>2679</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8874_11-46-31.700000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33307_11-46-31.75000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.706323.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.706323.jpg</td>\n",
       "      <td>2681</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8876_11-46-31.900000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33309_11-46-31.91666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.906525.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.906525.jpg</td>\n",
       "      <td>2683</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8879_11-46-32.133334...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33311_11-46-32.08333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.106727.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.106727.jpg</td>\n",
       "      <td>2688</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-31.959645.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-31.959645.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>2676</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8871_11-46-31.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33303_11-46-31.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.406020.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.406020.jpg</td>\n",
       "      <td>2678</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8873_11-46-31.600000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33305_11-46-31.58333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.606222.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.606222.jpg</td>\n",
       "      <td>2680</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8875_11-46-31.800000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33308_11-46-31.83333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.806424.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.806424.jpg</td>\n",
       "      <td>2682</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8877_11-46-32.000000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33310_11-46-32.00000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.006626.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.006626.jpg</td>\n",
       "      <td>2684</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8880_11-46-32.200000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33313_11-46-32.25000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.206828.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.206828.jpg</td>\n",
       "      <td>2689</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.059402.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.059402.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>2677</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8872_11-46-31.500000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33304_11-46-31.50000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.506121.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.506121.jpg</td>\n",
       "      <td>2679</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8874_11-46-31.700000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33307_11-46-31.75000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.706323.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.706323.jpg</td>\n",
       "      <td>2681</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8876_11-46-31.900000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33309_11-46-31.91666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.906525.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.906525.jpg</td>\n",
       "      <td>2683</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8879_11-46-32.133334...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33311_11-46-32.08333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.106727.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.106727.jpg</td>\n",
       "      <td>2685</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8881_11-46-32.300000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33314_11-46-32.33333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.306929.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.306929.jpg</td>\n",
       "      <td>2690</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.160005.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.160005.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>2678</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8873_11-46-31.600000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33305_11-46-31.58333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.606222.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.606222.jpg</td>\n",
       "      <td>2680</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8875_11-46-31.800000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33308_11-46-31.83333...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-31.806424.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-31.806424.jpg</td>\n",
       "      <td>2682</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8877_11-46-32.000000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33310_11-46-32.00000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.006626.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.006626.jpg</td>\n",
       "      <td>2684</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8880_11-46-32.200000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33313_11-46-32.25000...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.206828.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.206828.jpg</td>\n",
       "      <td>2686</td>\n",
       "      <td>scenario36/unit1/gps1/gps_8882_11-46-32.400000...</td>\n",
       "      <td>scenario36/unit2/gps1/gps_33315_11-46-32.41666...</td>\n",
       "      <td>scenario36/unit1/rgb5/frame_11-46-32.407030.jpg</td>\n",
       "      <td>scenario36/unit1/rgb6/frame_11-46-32.407030.jpg</td>\n",
       "      <td>2691</td>\n",
       "      <td>161</td>\n",
       "      <td>scenario36/unit1/pwr1/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr2/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr3/pwr_11-46-32.260057.txt</td>\n",
       "      <td>scenario36/unit1/pwr4/pwr_11-46-32.260057.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   scenario  x1_unique_index  \\\n",
       "0        36             2674   \n",
       "1        36             2675   \n",
       "2        36             2676   \n",
       "3        36             2677   \n",
       "4        36             2678   \n",
       "\n",
       "                                       x1_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8869_11-46-31.233334...   \n",
       "1  scenario36/unit1/gps1/gps_8870_11-46-31.300000...   \n",
       "2  scenario36/unit1/gps1/gps_8871_11-46-31.400000...   \n",
       "3  scenario36/unit1/gps1/gps_8872_11-46-31.500000...   \n",
       "4  scenario36/unit1/gps1/gps_8873_11-46-31.600000...   \n",
       "\n",
       "                                       x1_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33301_11-46-31.25000...   \n",
       "1  scenario36/unit2/gps1/gps_33302_11-46-31.33333...   \n",
       "2  scenario36/unit2/gps1/gps_33303_11-46-31.41666...   \n",
       "3  scenario36/unit2/gps1/gps_33304_11-46-31.50000...   \n",
       "4  scenario36/unit2/gps1/gps_33305_11-46-31.58333...   \n",
       "\n",
       "                                     x1_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.205818.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.305919.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-31.406020.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-31.506121.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-31.606222.jpg   \n",
       "\n",
       "                                     x1_unit1_rgb6  x2_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-31.205818.jpg             2676   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-31.305919.jpg             2677   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-31.406020.jpg             2678   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-31.506121.jpg             2679   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-31.606222.jpg             2680   \n",
       "\n",
       "                                       x2_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8871_11-46-31.400000...   \n",
       "1  scenario36/unit1/gps1/gps_8872_11-46-31.500000...   \n",
       "2  scenario36/unit1/gps1/gps_8873_11-46-31.600000...   \n",
       "3  scenario36/unit1/gps1/gps_8874_11-46-31.700000...   \n",
       "4  scenario36/unit1/gps1/gps_8875_11-46-31.800000...   \n",
       "\n",
       "                                       x2_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33303_11-46-31.41666...   \n",
       "1  scenario36/unit2/gps1/gps_33304_11-46-31.50000...   \n",
       "2  scenario36/unit2/gps1/gps_33305_11-46-31.58333...   \n",
       "3  scenario36/unit2/gps1/gps_33307_11-46-31.75000...   \n",
       "4  scenario36/unit2/gps1/gps_33308_11-46-31.83333...   \n",
       "\n",
       "                                     x2_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.406020.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.506121.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-31.606222.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-31.706323.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-31.806424.jpg   \n",
       "\n",
       "                                     x2_unit1_rgb6  x3_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-31.406020.jpg             2678   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-31.506121.jpg             2679   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-31.606222.jpg             2680   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-31.706323.jpg             2681   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-31.806424.jpg             2682   \n",
       "\n",
       "                                       x3_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8873_11-46-31.600000...   \n",
       "1  scenario36/unit1/gps1/gps_8874_11-46-31.700000...   \n",
       "2  scenario36/unit1/gps1/gps_8875_11-46-31.800000...   \n",
       "3  scenario36/unit1/gps1/gps_8876_11-46-31.900000...   \n",
       "4  scenario36/unit1/gps1/gps_8877_11-46-32.000000...   \n",
       "\n",
       "                                       x3_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33305_11-46-31.58333...   \n",
       "1  scenario36/unit2/gps1/gps_33307_11-46-31.75000...   \n",
       "2  scenario36/unit2/gps1/gps_33308_11-46-31.83333...   \n",
       "3  scenario36/unit2/gps1/gps_33309_11-46-31.91666...   \n",
       "4  scenario36/unit2/gps1/gps_33310_11-46-32.00000...   \n",
       "\n",
       "                                     x3_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.606222.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.706323.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-31.806424.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-31.906525.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-32.006626.jpg   \n",
       "\n",
       "                                     x3_unit1_rgb6  x4_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-31.606222.jpg             2680   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-31.706323.jpg             2681   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-31.806424.jpg             2682   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-31.906525.jpg             2683   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-32.006626.jpg             2684   \n",
       "\n",
       "                                       x4_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8875_11-46-31.800000...   \n",
       "1  scenario36/unit1/gps1/gps_8876_11-46-31.900000...   \n",
       "2  scenario36/unit1/gps1/gps_8877_11-46-32.000000...   \n",
       "3  scenario36/unit1/gps1/gps_8879_11-46-32.133334...   \n",
       "4  scenario36/unit1/gps1/gps_8880_11-46-32.200000...   \n",
       "\n",
       "                                       x4_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33308_11-46-31.83333...   \n",
       "1  scenario36/unit2/gps1/gps_33309_11-46-31.91666...   \n",
       "2  scenario36/unit2/gps1/gps_33310_11-46-32.00000...   \n",
       "3  scenario36/unit2/gps1/gps_33311_11-46-32.08333...   \n",
       "4  scenario36/unit2/gps1/gps_33313_11-46-32.25000...   \n",
       "\n",
       "                                     x4_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-31.806424.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-31.906525.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-32.006626.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-32.106727.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-32.206828.jpg   \n",
       "\n",
       "                                     x4_unit1_rgb6  x5_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-31.806424.jpg             2682   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-31.906525.jpg             2683   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-32.006626.jpg             2684   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-32.106727.jpg             2685   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-32.206828.jpg             2686   \n",
       "\n",
       "                                       x5_unit1_gps1  \\\n",
       "0  scenario36/unit1/gps1/gps_8877_11-46-32.000000...   \n",
       "1  scenario36/unit1/gps1/gps_8879_11-46-32.133334...   \n",
       "2  scenario36/unit1/gps1/gps_8880_11-46-32.200000...   \n",
       "3  scenario36/unit1/gps1/gps_8881_11-46-32.300000...   \n",
       "4  scenario36/unit1/gps1/gps_8882_11-46-32.400000...   \n",
       "\n",
       "                                       x5_unit2_gps1  \\\n",
       "0  scenario36/unit2/gps1/gps_33310_11-46-32.00000...   \n",
       "1  scenario36/unit2/gps1/gps_33311_11-46-32.08333...   \n",
       "2  scenario36/unit2/gps1/gps_33313_11-46-32.25000...   \n",
       "3  scenario36/unit2/gps1/gps_33314_11-46-32.33333...   \n",
       "4  scenario36/unit2/gps1/gps_33315_11-46-32.41666...   \n",
       "\n",
       "                                     x5_unit1_rgb5  \\\n",
       "0  scenario36/unit1/rgb5/frame_11-46-32.006626.jpg   \n",
       "1  scenario36/unit1/rgb5/frame_11-46-32.106727.jpg   \n",
       "2  scenario36/unit1/rgb5/frame_11-46-32.206828.jpg   \n",
       "3  scenario36/unit1/rgb5/frame_11-46-32.306929.jpg   \n",
       "4  scenario36/unit1/rgb5/frame_11-46-32.407030.jpg   \n",
       "\n",
       "                                     x5_unit1_rgb6  y1_unique_index  \\\n",
       "0  scenario36/unit1/rgb6/frame_11-46-32.006626.jpg             2687   \n",
       "1  scenario36/unit1/rgb6/frame_11-46-32.106727.jpg             2688   \n",
       "2  scenario36/unit1/rgb6/frame_11-46-32.206828.jpg             2689   \n",
       "3  scenario36/unit1/rgb6/frame_11-46-32.306929.jpg             2690   \n",
       "4  scenario36/unit1/rgb6/frame_11-46-32.407030.jpg             2691   \n",
       "\n",
       "   y1_unit1_overall-beam                                  y1_unit1_pwr1  \\\n",
       "0                    161  scenario36/unit1/pwr1/pwr_11-46-31.859441.txt   \n",
       "1                    161  scenario36/unit1/pwr1/pwr_11-46-31.959645.txt   \n",
       "2                    161  scenario36/unit1/pwr1/pwr_11-46-32.059402.txt   \n",
       "3                    161  scenario36/unit1/pwr1/pwr_11-46-32.160005.txt   \n",
       "4                    161  scenario36/unit1/pwr1/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr2  \\\n",
       "0  scenario36/unit1/pwr2/pwr_11-46-31.859441.txt   \n",
       "1  scenario36/unit1/pwr2/pwr_11-46-31.959645.txt   \n",
       "2  scenario36/unit1/pwr2/pwr_11-46-32.059402.txt   \n",
       "3  scenario36/unit1/pwr2/pwr_11-46-32.160005.txt   \n",
       "4  scenario36/unit1/pwr2/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr3  \\\n",
       "0  scenario36/unit1/pwr3/pwr_11-46-31.859441.txt   \n",
       "1  scenario36/unit1/pwr3/pwr_11-46-31.959645.txt   \n",
       "2  scenario36/unit1/pwr3/pwr_11-46-32.059402.txt   \n",
       "3  scenario36/unit1/pwr3/pwr_11-46-32.160005.txt   \n",
       "4  scenario36/unit1/pwr3/pwr_11-46-32.260057.txt   \n",
       "\n",
       "                                   y1_unit1_pwr4  \n",
       "0  scenario36/unit1/pwr4/pwr_11-46-31.859441.txt  \n",
       "1  scenario36/unit1/pwr4/pwr_11-46-31.959645.txt  \n",
       "2  scenario36/unit1/pwr4/pwr_11-46-32.059402.txt  \n",
       "3  scenario36/unit1/pwr4/pwr_11-46-32.160005.txt  \n",
       "4  scenario36/unit1/pwr4/pwr_11-46-32.260057.txt  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scen_idx = 36\n",
    "csv_train = r'D:\\Python\\Multi Modal Beam Prediction with Deep Learning\\data\\raw\\scenario36\\deepsense_challenge2023_trainset.csv'\n",
    "csv_dict_path = rf'D:\\Python\\Multi Modal Beam Prediction with Deep Learning\\data\\raw\\scenario{scen_idx}\\scenario{scen_idx}.p'\n",
    "\n",
    "with open(csv_dict_path, 'rb') as fp:\n",
    "    csv_dict = pickle.load(fp)\n",
    "\n",
    "df_train = pd.read_csv(csv_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m pd\u001b[38;5;241m.\u001b[39mset_option(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay.max_columns\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m----> 3\u001b[0m \u001b[43mdf_train\u001b[49m\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_train' is not defined"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data:   0%|          | 0/23187 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading data: 100%|██████████| 23187/23187 [00:28<00:00, 819.55it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load all positions\n",
    "samples_of_scen = np.where(df_train['scenario'] == scen_idx)[0]\n",
    "n_samples = len(samples_of_scen)\n",
    "\n",
    "X_SIZE = 5      # 5 input samples\n",
    "N_GPS = 2       # 2 GPSs (unit1 and unit2)\n",
    "N_GPS_COORD = 2 # 2 GPS coords (latitude & longitude)\n",
    "N_ARR = 4       # 4 arrays\n",
    "N_BEAMS = 64    # 64 beams per array\n",
    "IDX_COL1 = 'unique_index' # index col in the training CSV\n",
    "IDX_COL2 = 'abs_index'    # index col in the CSVs of the V2V dataset \n",
    "                          # this indices are the same, just dif names\n",
    "loaded_positions = set()\n",
    "train_positions = np.zeros((n_samples, X_SIZE, N_GPS, N_GPS_COORD))\n",
    "y_pos1 = np.zeros((n_samples, N_GPS_COORD))\n",
    "y_pos2 = np.zeros((n_samples, N_GPS_COORD))\n",
    "y_pwrs = np.zeros((n_samples, N_ARR, N_BEAMS))\n",
    "\n",
    "# Loop over each sample in the training data\n",
    "for sample_idx in tqdm(range(n_samples), desc='Loading data'):\n",
    "    # Get the current training sample\n",
    "    train_sample = samples_of_scen[sample_idx]\n",
    "    \n",
    "    # Loop over each position index on the X axis\n",
    "    for x_idx in range(X_SIZE):\n",
    "        # Find the absolute relative index in the CSV DataFrame for the current training sample\n",
    "        abs_idx_relative_index = (csv_dict[IDX_COL2] == df_train[f'x{x_idx+1}_'+IDX_COL1][train_sample])\n",
    "        \n",
    "        # Fill the training positions for the current sample and current X index\n",
    "        # GPS positions of 'unit1' and 'unit2' are stored in train_positions\n",
    "        # Index [0, :] is used for 'unit1' GPS coordinates, and index [1, :] is used for 'unit2' GPS coordinates\n",
    "        train_positions[sample_idx, x_idx, 0, :] = csv_dict['unit1_gps1'][abs_idx_relative_index]\n",
    "        train_positions[sample_idx, x_idx, 1, :] = csv_dict['unit2_gps1'][abs_idx_relative_index]\n",
    "\n",
    "    # Find the index for the ground truth position 'y' in the CSV dictionary DataFrame\n",
    "    y_idx = (csv_dict[IDX_COL2] == df_train['y1_'+IDX_COL1][train_sample])\n",
    "\n",
    "    # Store the GPS positions for 'unit1' and 'unit2' corresponding to the ground truth 'y' position\n",
    "    y_pos1[sample_idx] = csv_dict['unit1_gps1'][y_idx]\n",
    "    y_pos2[sample_idx] = csv_dict['unit2_gps1'][y_idx]\n",
    "\n",
    "    # Loop over each antenna array to store the power readings corresponding to the ground truth 'y' position\n",
    "    for arr_idx in range(N_ARR):\n",
    "        y_pwrs[sample_idx, arr_idx] = csv_dict[f'unit1_pwr{arr_idx+1}'][y_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract ground truth beams for 'unit1' from the DataFrame, based on the selected samples\n",
    "y_true_beams = df_train['y1_unit1_overall-beam'].values[samples_of_scen] \n",
    "\n",
    "y_pwrs_reshaped = y_pwrs.reshape((n_samples, -1)) # (23187, 256)\n",
    "# Sort the power readings in descending order to get the indices of the beams with highest power\n",
    "all_true_beams = np.flip(np.argsort(y_pwrs_reshaped, axis=1), axis=1) # (23187, 256)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00012933, 0.00017002, 0.00016716, ..., 0.00015581, 0.0001499 ,\n",
       "        0.00014879],\n",
       "       [0.00012251, 0.00016665, 0.00017345, ..., 0.0001511 , 0.00015527,\n",
       "        0.00015383],\n",
       "       [0.00012754, 0.00015688, 0.00016276, ..., 0.00015055, 0.00014433,\n",
       "        0.00015737],\n",
       "       ...,\n",
       "       [0.00012266, 0.00014684, 0.00014105, ..., 0.00014967, 0.00015166,\n",
       "        0.00015794],\n",
       "       [0.00011438, 0.00014286, 0.00015644, ..., 0.00015184, 0.0001382 ,\n",
       "        0.0001454 ],\n",
       "       [0.00012457, 0.0001452 , 0.00015113, ..., 0.00015858, 0.00015953,\n",
       "        0.00017267]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pwrs_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Estimating input positions: 100%|██████████| 23187/23187 [00:02<00:00, 9192.90it/s] \n",
      "Estimating input positions: 100%|██████████| 23187/23187 [00:02<00:00, 8067.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# Define the time difference between consecutive input samples and the time difference from the last input to the output\n",
    "delta_input = 0.2  # time difference between input samples [s]\n",
    "delta_output = 0.5  # time difference from last input to output [s]\n",
    "\n",
    "# Estimate positions for 'unit1' GPS data using the given time differences\n",
    "gps1_est_pos = estimate_positions(train_positions[:, :, 0, :], delta_input, delta_output) # (23187, 5, 2)\n",
    "\n",
    "# Estimate positions for 'unit2' GPS data using the given time differences\n",
    "gps2_est_pos = estimate_positions(train_positions[:, :, 1, :], delta_input, delta_output) # (23187, 5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  33.42170575, -111.93017142],\n",
       "       [  33.42170569, -111.9301714 ],\n",
       "       [  33.42170566, -111.93017142],\n",
       "       ...,\n",
       "       [  33.37800926, -111.96744191],\n",
       "       [  33.37801588, -111.96744182],\n",
       "       [  33.37801599, -111.96744184]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gps1_est_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 2.782557746704443\n",
      "Epoch [2/10], Loss: 5.926279321512369e-07\n",
      "Epoch [3/10], Loss: 6.149082703315841e-07\n",
      "Epoch [4/10], Loss: 6.240463482262928e-07\n",
      "Epoch [5/10], Loss: 6.549802537487114e-07\n",
      "Epoch [6/10], Loss: 7.301349869152788e-07\n",
      "Epoch [7/10], Loss: 7.316948440451662e-05\n",
      "Epoch [8/10], Loss: 0.0013482792166231393\n",
      "Epoch [9/10], Loss: 0.0013670241568871228\n",
      "Epoch [10/10], Loss: 0.0014382334439011287\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convertendo os dados de entrada para tensores PyTorch\n",
    "input_positions_tensor = torch.tensor(train_positions[:, :, 0, :], dtype=torch.float32)\n",
    "\n",
    "class CNNPositionEstimator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNPositionEstimator, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))\n",
    "        x = torch.relu(self.conv3(x))\n",
    "        x = torch.max_pool1d(x, kernel_size=x.size(-1))  # Global max pooling\n",
    "        x = torch.relu(self.fc1(x.squeeze()))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instanciando o modelo\n",
    "model = CNNPositionEstimator()\n",
    "\n",
    "# Definindo a função de perda e o otimizador\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Treinamento do modelo\n",
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0.0\n",
    "    for i in range(0, len(input_positions_tensor), batch_size):\n",
    "        inputs = input_positions_tensor[i:i+batch_size]\n",
    "        \n",
    "        # Zerando os gradientes\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs.permute(0, 2, 1))  # Trocando as dimensões para se adequar ao modelo\n",
    "\n",
    "        # Calculando a perda\n",
    "        loss = criterion(outputs, inputs[:, -1, :])  # Comparando a saída com a última posição conhecida\n",
    "\n",
    "        # Backward pass e otimização\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss / len(input_positions_tensor)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
